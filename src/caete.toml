# Configuration file for CAETE model

# Fisrt day of each month
# doy_months = [1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335]
# doy_months = [32, 91, 152, 213, 274, 335]
doy_months = [1, 16, 31, 46, 61, 76, 91, 106, 121, 136, 151, 166, 181, 196, 211, 226, 241, 256, 271, 286, 301, 316, 331, 346, 361]

[output]
output_dir = "../outputs" # Directory where the output files will be saved.

# Compression parameters for the intermediate files of a region.
# The intermediate files are used to store the gridcells during the model run,
# avoiding the need to keep all gridcells in memory. The intermediate files are used
# by the state files to start new runs from a previous state.
# State files based on Intermediate files with cleaned gridcells
# are used to manage post processing of output data
[compression]
# Compressor to use for joblib.dump.
# Note that "lz4" requires the lz4 package installed (Faster/low compression).
compressor = "lz4" # compressors for joblib.dump ["lzma", "bz2", "lz4", "gzip", "xz"]
rate = 2 # compression rate for joblib.dump. 0-9, where 0 is no compression and 9 is maximum compression.

[input_handler]
# Input handler configuration. Used to read input data.

# "ih" uses the new input handler which is more flexible and allows for different input formats
input_method = "ih" # "legacy" or "ih". Legacy uses the old method of passing filepaths to the gridcells. If legacy is defined, input_type has no effect.

input_type = "netcdf" # Type of input data. The options are "netcdf" & "bz2"

# The netcdf files used are chunked in an optimal way for reading.
# The sequential reading is faster than the parallel reading. Only have effect if input_type is "netcdf" and input_method is "ih".
mp = false # Use MPI for reading netcdf files.


# Configs for parallelization
[multiprocessing]
nprocs= 128 # Threads used to post process the output. Not used by the model itself.

# max_processes limit the number of python processes used to run the model.
# Should not be larger than the number of available logical cores.
max_processes = 16 # Number of python processes used to run the model.

# Number of threads used by OpenMP which each python process can use.
# Must compile the extension module with OpenMP support to have any effect.
# If you set this to 0, OpenMP will not be used. Even if the extension
# module is compiled with OpenMP support.
# If the value is more than 1, make sure that max_processes is not larger
# than the number of logical cores available in your machine.
# E.g., if you have 8 logical cores, you can set omp_num_threads to 2 and max_processes to 4.
# This will use 2 threads per process, resulting in a total of 8 threads.
# Currently setting multithreading degrades performance (overhead of creating new threads), i.e.,
# the model runs faster if you set max_processes to the number of logical
# cores available in your machine and compile the extension module without OpenMP support.
# If you are running a number of gridcells smaller than the number of logical cores,
# you can set max_processes to the number of gridcells and omp_num_threads to >1.
# This will make the model run a little faster.
omp_num_threads = 1

# COnversion factors used to convert units of input data
[conversion_factors_isimip]
tas = 273.15  # K to degC (sub) [input(K) to model(°C)]
pr = 86400.0  # kg m-2 s-1 to mm day-1 (mult) [input(kg m-2 s-1) to model(mm day-1)]
ps = 0.01  # Pa to hPa (mult) [input(Pa) to model(hPa)]
rhs = 0.01  # % to kg kg-1  (mult) [input(%) to model(kg kg-1)]

# Convert W m⁻² to J m⁻² day⁻¹:
# 1 W = 1 J/s
# 1 day = 86400 s
# So, 1 W m⁻² = 86400 J m⁻² day⁻¹

# Fraction of PAR:
# Multiply by 0.5 (if we assume 50% of total solar is PAR).

# Joules per mol photons:
# The energy of 1 mol photons in PAR is about 218,000 J (2.18e5 J).

# (photons) m⁻² day⁻¹ = (W m⁻²) * 86400 * 0.5 / 218000
# = (W m⁻²) * 0.198
rsds = 0.198
# This was wrong in the original config, it was 2.2936e-06:
# rsds = 2.2936e-06 # 0.5 / 2.18e5 (mult) [input(W m-2) to model(mol(photons) m-2 day-1)]

# Metacommunity configuration. Used at compile- and run-time.
[metacomm]

# Number of communities to be considered in the metacommunity;
# Set to 1 to run the model in single community mode.
# You shouldn't set this to a value larger than 30 as it will
# increase the memory usage and the time to run the model.
n = 1 # Effects only in runtime, recompilatio not needed.

# Maximum number of PLS to be considered in each community.
# Very large values CAN cause (>3000) stack overflow errors.
# If you wish to use more than 3000 PLS, you should exchange the
# budget_fixed.F90 (it allocates arrays in the stack) in
# the Makefile_win by budget.F90 (heap allocation).
# The budget.F90 is slower than budget_fixed.F90, but it
# allows for larger number of PLS.
# The final number of slots for PLSs in the model is equal to n * npls_max.
# Changes here and in ntraits will not be applied to the model (fortran extension module)
# unless you recompile it. THe model will not run if you compile
# it with a value and then run it with a different value.

npls_max = 1000
 # number of traits in a PLS
ntraits = 17

[crs]
res = 0.5
xres = 0.5
yres = 0.5
datum = "WGS84"
epsg_id = 4326
proj4 = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
epsg_long_name = "World Geodetic System 1984"
lat_units = "degrees_north"
lon_units = "degrees_east"
lat_zero = 90
lon_zero = -180

[fertilization]
afex_mode =  "N"  # "P" or "NP"
n = 12.5  # (12.5 g m-2 y-1 == 125 kg ha-1 y-1)
p = 5.0   # (5 g m-2 y-1 == 50 kg ha-1 y-1)
